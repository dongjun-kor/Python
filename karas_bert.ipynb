{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "karas_bert",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMfqHFHNA6DGbVUjgmEav/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dongjun-kor/Python/blob/main/karas_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xjSkRzzEAmbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82a4cdb-f12f-4cc1-84cd-cfe2c957774e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-bert\n",
            "  Downloading keras-bert-0.89.0.tar.gz (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-bert) (1.21.6)\n",
            "Collecting keras-transformer==0.40.0\n",
            "  Downloading keras-transformer-0.40.0.tar.gz (9.7 kB)\n",
            "Collecting keras-pos-embd==0.13.0\n",
            "  Downloading keras-pos-embd-0.13.0.tar.gz (5.6 kB)\n",
            "Collecting keras-multi-head==0.29.0\n",
            "  Downloading keras-multi-head-0.29.0.tar.gz (13 kB)\n",
            "Collecting keras-layer-normalization==0.16.0\n",
            "  Downloading keras-layer-normalization-0.16.0.tar.gz (3.9 kB)\n",
            "Collecting keras-position-wise-feed-forward==0.8.0\n",
            "  Downloading keras-position-wise-feed-forward-0.8.0.tar.gz (4.1 kB)\n",
            "Collecting keras-embed-sim==0.10.0\n",
            "  Downloading keras-embed-sim-0.10.0.tar.gz (3.6 kB)\n",
            "Collecting keras-self-attention==0.51.0\n",
            "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
            "Building wheels for collected packages: keras-bert, keras-transformer, keras-embed-sim, keras-layer-normalization, keras-multi-head, keras-pos-embd, keras-position-wise-feed-forward, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.89.0-py3-none-any.whl size=33517 sha256=ae90a0daded005ffec802ad1732b8206d240586ad1605344b24b63a9b5b25bfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/e8/45/842b3a39831261aef9154b907eacbc4ac99499a99ae829b06f\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.40.0-py3-none-any.whl size=12305 sha256=8e4675e6b4c2ff43834d11ee78b06e9d60194b383fac776d27738c0e0e1ce1b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/68/26/692ed21edd832833c3b0a0e21615bcacd99ca458b3f9ed571f\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.10.0-py3-none-any.whl size=3960 sha256=067029120ba9e79cc83a99b7a86c07eb835626aba912304c63049f711e142d8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/67/b5/d847588d075895281e1cf5590f819bd4cf076a554872268bd5\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.16.0-py3-none-any.whl size=4668 sha256=4473ef8ee428fd985de9317b1dae51016f594f9f1bd63ebb6690ff7c5c004f7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/5d/1c/2e619f594f69fbcf8bc20943b27d414871c409be053994813e\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.29.0-py3-none-any.whl size=14993 sha256=18ce2054a7d84644e64ae13673d31667c2acba7e90f2d252fc3b648f6b0ac645\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/aa/3c/9d15d24005179dae08ff291ce99c754b296347817d076fd9fb\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.13.0-py3-none-any.whl size=6962 sha256=ca2fc55cb83e0385ce7b4f58bb1731b35aa9bfdd014c2503af61a630fe4a3228\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/c1/a0/dc44fcf68c857b7ff6be9a97e675e5adf51022eff1169b042f\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.8.0-py3-none-any.whl size=4983 sha256=7bb491c2a3539c971fd4727b6b15f0ba61891cd932d5eff9c315041012212af4\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/75/6f/d42f6e051506f442daeba53ff1e2d21a5f20ef8c411610f2bb\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18912 sha256=fce79d4a9cbe697cac6099940c02ce903be8348368184eae0ceba227ca35665b\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/b1/a8/5ee00cc137940b2f6fa198212e8f45d813d0e0d9c3a04035a3\n",
            "Successfully built keras-bert keras-transformer keras-embed-sim keras-layer-normalization keras-multi-head keras-pos-embd keras-position-wise-feed-forward keras-self-attention\n",
            "Installing collected packages: keras-self-attention, keras-position-wise-feed-forward, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-embed-sim, keras-transformer, keras-bert\n",
            "Successfully installed keras-bert-0.89.0 keras-embed-sim-0.10.0 keras-layer-normalization-0.16.0 keras-multi-head-0.29.0 keras-pos-embd-0.13.0 keras-position-wise-feed-forward-0.8.0 keras-self-attention-0.51.0 keras-transformer-0.40.0\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-bert"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "viWVSXG8AsGC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66MxAsE6AtEa",
        "outputId": "41ddee1c-0a91-4a85-8b4a-5c61d1975696"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'gdrive/MyDrive/Colab Notebooks/'"
      ],
      "metadata": {
        "id": "H9GPC3P3AuR5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "EqtqCPAFAvft"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "import keras as keras\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from keras import Input, Model\n",
        "from keras import optimizers\n",
        "\n",
        "import codecs\n",
        "from tqdm import tqdm\n",
        "import shutil"
      ],
      "metadata": {
        "id": "OG-if09wAwz1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_bert import load_trained_model_from_checkpoint, load_vocabulary\n",
        "from keras_bert import Tokenizer\n",
        "from keras_bert import AdamWarmup, calc_train_steps"
      ],
      "metadata": {
        "id": "QqkYkZTWAwtB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def copytree(src, dst, symlinks=False, ignore = None):\n",
        "  for item in os.listdir(src):\n",
        "    s = os.path.join(src, item)\n",
        "    d = os.path.join(dst, item)\n",
        "    if os.path.isdir(s):\n",
        "      shutil.copytree(s, d, symlinks, ignore)\n",
        "    else:\n",
        "      shutil.copy2(s, d)"
      ],
      "metadata": {
        "id": "ZwibN66kAyrW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#os.makedirs('bert')\n",
        "# 존재하면 error 뜸"
      ],
      "metadata": {
        "id": "_8vL45PjAz6a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wget을 활용해서 bert 모델 다운로드 가능\n",
        "import os\n",
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "\n",
        "if \"bert\" not in os.listdir():\n",
        "  os.makedirs(\"bert\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "import zipfile\n",
        "import shutil\n",
        "         \n",
        "bert_zip = zipfile.ZipFile('multi_cased_L-12_H-768_A-12.zip')\n",
        "bert_zip.extractall('bert')\n",
        " \n",
        "bert_zip.close()\n",
        "\n",
        "def copytree(src, dst, symlinks=False, ignore=None):\n",
        "    for item in os.listdir(src):\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isdir(s):\n",
        "            shutil.copytree(s, d, symlinks, ignore)\n",
        "        else:\n",
        "            shutil.copy2(s, d)\n",
        "\n",
        "copytree(\"bert/multi_cased_L-12_H-768_A-12\", \"bert\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsse1fDlCBiT",
        "outputId": "8ec56423-98a2-4a77-c58f-3eadcc59935b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-15 09:24:51--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.199.128, 74.125.20.128, 108.177.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.199.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M   249MB/s    in 2.5s    \n",
            "\n",
            "2022-05-15 09:24:53 (249 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#copytree(os.path.join(path, 'BERT_MODEL'), 'bert')"
      ],
      "metadata": {
        "id": "1oMA3fZQA0uV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 가져오기"
      ],
      "metadata": {
        "id": "Ofzf3mhEA4Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train = pd.read_csv(\"/content/gdrive/MyDrive/sIPCcode1.csv\",encoding=\"euc-kr\") # train dataset 가져오기\n",
        "#test =  pd.read_csv(\"gdrive/MyDrive/Colab Notebooks/Dataset/news_test.csv\") # test dataset 가져오기"
      ],
      "metadata": {
        "id": "CLVNXqFGA2T0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/gdrive/MyDrive/dataset1.csv\",encoding=\"euc-kr\")\n",
        "#test = pd.read_table(\"nsmc/\"+\"ratings_test.txt\")"
      ],
      "metadata": {
        "id": "M2oVX_M2MYrC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "datIXlx_C77V",
        "outputId": "93881ccc-4c19-4145-bc92-0bbe3c2538c7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                ID                                            content  info  \\\n",
              "0      A01B-001/00     Hand tools (edge trimmers for lawns A01G3/06 )     0   \n",
              "1      A01B-001/02                                    Spades; Shovels     0   \n",
              "2      A01B-001/04                                         with teeth     0   \n",
              "3      A01B-001/06                             Hoes; Hand cultivators     0   \n",
              "4      A01B-001/08                                with a single blade     0   \n",
              "...            ...                                                ...   ...   \n",
              "67354  H01B-017/64       with conductive admixtures inserts or layers     7   \n",
              "67355  H01B-017/66   Joining insulating bodies together, e.g. by b...     7   \n",
              "67356  H01B-019/00  Apparatus or processes specially adapted for m...     7   \n",
              "67357  H01B-019/02                               Drying; Impregnating     7   \n",
              "67358  H01B-019/04      Treating the surfaces, e.g. applying coatings     7   \n",
              "\n",
              "      cat  \n",
              "0       A  \n",
              "1       A  \n",
              "2       A  \n",
              "3       A  \n",
              "4       A  \n",
              "...    ..  \n",
              "67354   H  \n",
              "67355   H  \n",
              "67356   H  \n",
              "67357   H  \n",
              "67358   H  \n",
              "\n",
              "[67359 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0a2f5f1a-0318-46be-b6b1-ff0fcf6450b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>content</th>\n",
              "      <th>info</th>\n",
              "      <th>cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A01B-001/00</td>\n",
              "      <td>Hand tools (edge trimmers for lawns A01G3/06 )</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A01B-001/02</td>\n",
              "      <td>Spades; Shovels</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A01B-001/04</td>\n",
              "      <td>with teeth</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A01B-001/06</td>\n",
              "      <td>Hoes; Hand cultivators</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A01B-001/08</td>\n",
              "      <td>with a single blade</td>\n",
              "      <td>0</td>\n",
              "      <td>A</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67354</th>\n",
              "      <td>H01B-017/64</td>\n",
              "      <td>with conductive admixtures inserts or layers</td>\n",
              "      <td>7</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67355</th>\n",
              "      <td>H01B-017/66</td>\n",
              "      <td>Joining insulating bodies together, e.g. by b...</td>\n",
              "      <td>7</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67356</th>\n",
              "      <td>H01B-019/00</td>\n",
              "      <td>Apparatus or processes specially adapted for m...</td>\n",
              "      <td>7</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67357</th>\n",
              "      <td>H01B-019/02</td>\n",
              "      <td>Drying; Impregnating</td>\n",
              "      <td>7</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67358</th>\n",
              "      <td>H01B-019/04</td>\n",
              "      <td>Treating the surfaces, e.g. applying coatings</td>\n",
              "      <td>7</td>\n",
              "      <td>H</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67359 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a2f5f1a-0318-46be-b6b1-ff0fcf6450b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0a2f5f1a-0318-46be-b6b1-ff0fcf6450b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0a2f5f1a-0318-46be-b6b1-ff0fcf6450b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 128 # 문장 최대 길이\n",
        "BATCH_SIZE = 32 # Batch size\n",
        "EPOCHS = 3 # Epochs \n",
        "LR = 1e-5 # Learning Rate\n",
        "\n",
        "pretrained_path = 'gdrive/MyDrive/Colab Notebooks/BERT_MODEL'\n",
        "config_path = os.path.join(pretrained_path, 'bert_config.json')\n",
        "checkpoint_path = os.path.join(pretrained_path, 'bert_model.ckpt')\n",
        "vocab_path = os.path.join(pretrained_path, 'vocab.txt')\n",
        "\n",
        "DATA_COLUMN = 'content' # 분석할 문장의 Column\n",
        "LABEL_COLUMN = 'info' # Label Column"
      ],
      "metadata": {
        "id": "H0UBQMu6B0w4"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABEL_COLUMN = 'info' # Label Column\n",
        "\n",
        "token_dict = {}\n",
        "\n",
        "with codecs.open('/content/bert_base_uncased/vocab.txt', 'r', encoding='utf-8') as reader:\n",
        "  for line in reader:\n",
        "    token = line.strip()\n",
        "    if \"_\" in token:\n",
        "      token = token.replace(\"_\",\"\")\n",
        "      token = \"##\" + token\n",
        "    token_dict[token] = len(token_dict)"
      ],
      "metadata": {
        "id": "LOGuXGiSB3EK"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**허깅페이스에서 가져오기**"
      ],
      "metadata": {
        "id": "RTsc0WUEUPql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token_dict"
      ],
      "metadata": {
        "id": "MR1gauGeCqrI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43481121-06ea-47be-f311-de8ef35560e8"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'[PAD]': 0,\n",
              " '[unused0]': 1,\n",
              " '[unused1]': 2,\n",
              " '[unused2]': 3,\n",
              " '[unused3]': 4,\n",
              " '[unused4]': 5,\n",
              " '[unused5]': 6,\n",
              " '[unused6]': 7,\n",
              " '[unused7]': 8,\n",
              " '[unused8]': 9,\n",
              " '[unused9]': 10,\n",
              " '[unused10]': 11,\n",
              " '[unused11]': 12,\n",
              " '[unused12]': 13,\n",
              " '[unused13]': 14,\n",
              " '[unused14]': 15,\n",
              " '[unused15]': 16,\n",
              " '[unused16]': 17,\n",
              " '[unused17]': 18,\n",
              " '[unused18]': 19,\n",
              " '[unused19]': 20,\n",
              " '[unused20]': 21,\n",
              " '[unused21]': 22,\n",
              " '[unused22]': 23,\n",
              " '[unused23]': 24,\n",
              " '[unused24]': 25,\n",
              " '[unused25]': 26,\n",
              " '[unused26]': 27,\n",
              " '[unused27]': 28,\n",
              " '[unused28]': 29,\n",
              " '[unused29]': 30,\n",
              " '[unused30]': 31,\n",
              " '[unused31]': 32,\n",
              " '[unused32]': 33,\n",
              " '[unused33]': 34,\n",
              " '[unused34]': 35,\n",
              " '[unused35]': 36,\n",
              " '[unused36]': 37,\n",
              " '[unused37]': 38,\n",
              " '[unused38]': 39,\n",
              " '[unused39]': 40,\n",
              " '[unused40]': 41,\n",
              " '[unused41]': 42,\n",
              " '[unused42]': 43,\n",
              " '[unused43]': 44,\n",
              " '[unused44]': 45,\n",
              " '[unused45]': 46,\n",
              " '[unused46]': 47,\n",
              " '[unused47]': 48,\n",
              " '[unused48]': 49,\n",
              " '[unused49]': 50,\n",
              " '[unused50]': 51,\n",
              " '[unused51]': 52,\n",
              " '[unused52]': 53,\n",
              " '[unused53]': 54,\n",
              " '[unused54]': 55,\n",
              " '[unused55]': 56,\n",
              " '[unused56]': 57,\n",
              " '[unused57]': 58,\n",
              " '[unused58]': 59,\n",
              " '[unused59]': 60,\n",
              " '[unused60]': 61,\n",
              " '[unused61]': 62,\n",
              " '[unused62]': 63,\n",
              " '[unused63]': 64,\n",
              " '[unused64]': 65,\n",
              " '[unused65]': 66,\n",
              " '[unused66]': 67,\n",
              " '[unused67]': 68,\n",
              " '[unused68]': 69,\n",
              " '[unused69]': 70,\n",
              " '[unused70]': 71,\n",
              " '[unused71]': 72,\n",
              " '[unused72]': 73,\n",
              " '[unused73]': 74,\n",
              " '[unused74]': 75,\n",
              " '[unused75]': 76,\n",
              " '[unused76]': 77,\n",
              " '[unused77]': 78,\n",
              " '[unused78]': 79,\n",
              " '[unused79]': 80,\n",
              " '[unused80]': 81,\n",
              " '[unused81]': 82,\n",
              " '[unused82]': 83,\n",
              " '[unused83]': 84,\n",
              " '[unused84]': 85,\n",
              " '[unused85]': 86,\n",
              " '[unused86]': 87,\n",
              " '[unused87]': 88,\n",
              " '[unused88]': 89,\n",
              " '[unused89]': 90,\n",
              " '[unused90]': 91,\n",
              " '[unused91]': 92,\n",
              " '[unused92]': 93,\n",
              " '[unused93]': 94,\n",
              " '[unused94]': 95,\n",
              " '[unused95]': 96,\n",
              " '[unused96]': 97,\n",
              " '[unused97]': 98,\n",
              " '[unused98]': 99,\n",
              " '[UNK]': 100,\n",
              " '[CLS]': 101,\n",
              " '[SEP]': 102,\n",
              " '[MASK]': 103,\n",
              " '[unused99]': 104,\n",
              " '[unused100]': 105,\n",
              " '[unused101]': 106,\n",
              " '[unused102]': 107,\n",
              " '[unused103]': 108,\n",
              " '[unused104]': 109,\n",
              " '[unused105]': 110,\n",
              " '[unused106]': 111,\n",
              " '[unused107]': 112,\n",
              " '[unused108]': 113,\n",
              " '[unused109]': 114,\n",
              " '[unused110]': 115,\n",
              " '[unused111]': 116,\n",
              " '[unused112]': 117,\n",
              " '[unused113]': 118,\n",
              " '[unused114]': 119,\n",
              " '[unused115]': 120,\n",
              " '[unused116]': 121,\n",
              " '[unused117]': 122,\n",
              " '[unused118]': 123,\n",
              " '[unused119]': 124,\n",
              " '[unused120]': 125,\n",
              " '[unused121]': 126,\n",
              " '[unused122]': 127,\n",
              " '[unused123]': 128,\n",
              " '[unused124]': 129,\n",
              " '[unused125]': 130,\n",
              " '[unused126]': 131,\n",
              " '[unused127]': 132,\n",
              " '[unused128]': 133,\n",
              " '[unused129]': 134,\n",
              " '[unused130]': 135,\n",
              " '[unused131]': 136,\n",
              " '[unused132]': 137,\n",
              " '[unused133]': 138,\n",
              " '[unused134]': 139,\n",
              " '[unused135]': 140,\n",
              " '[unused136]': 141,\n",
              " '[unused137]': 142,\n",
              " '[unused138]': 143,\n",
              " '[unused139]': 144,\n",
              " '[unused140]': 145,\n",
              " '[unused141]': 146,\n",
              " '[unused142]': 147,\n",
              " '[unused143]': 148,\n",
              " '[unused144]': 149,\n",
              " '[unused145]': 150,\n",
              " '[unused146]': 151,\n",
              " '[unused147]': 152,\n",
              " '[unused148]': 153,\n",
              " '[unused149]': 154,\n",
              " '[unused150]': 155,\n",
              " '[unused151]': 156,\n",
              " '[unused152]': 157,\n",
              " '[unused153]': 158,\n",
              " '[unused154]': 159,\n",
              " '[unused155]': 160,\n",
              " '[unused156]': 161,\n",
              " '[unused157]': 162,\n",
              " '[unused158]': 163,\n",
              " '[unused159]': 164,\n",
              " '[unused160]': 165,\n",
              " '[unused161]': 166,\n",
              " '[unused162]': 167,\n",
              " '[unused163]': 168,\n",
              " '[unused164]': 169,\n",
              " '[unused165]': 170,\n",
              " '[unused166]': 171,\n",
              " '[unused167]': 172,\n",
              " '[unused168]': 173,\n",
              " '[unused169]': 174,\n",
              " '[unused170]': 175,\n",
              " '[unused171]': 176,\n",
              " '[unused172]': 177,\n",
              " '[unused173]': 178,\n",
              " '[unused174]': 179,\n",
              " '[unused175]': 180,\n",
              " '[unused176]': 181,\n",
              " '[unused177]': 182,\n",
              " '[unused178]': 183,\n",
              " '[unused179]': 184,\n",
              " '[unused180]': 185,\n",
              " '[unused181]': 186,\n",
              " '[unused182]': 187,\n",
              " '[unused183]': 188,\n",
              " '[unused184]': 189,\n",
              " '[unused185]': 190,\n",
              " '[unused186]': 191,\n",
              " '[unused187]': 192,\n",
              " '[unused188]': 193,\n",
              " '[unused189]': 194,\n",
              " '[unused190]': 195,\n",
              " '[unused191]': 196,\n",
              " '[unused192]': 197,\n",
              " '[unused193]': 198,\n",
              " '[unused194]': 199,\n",
              " '[unused195]': 200,\n",
              " '[unused196]': 201,\n",
              " '[unused197]': 202,\n",
              " '[unused198]': 203,\n",
              " '[unused199]': 204,\n",
              " '[unused200]': 205,\n",
              " '[unused201]': 206,\n",
              " '[unused202]': 207,\n",
              " '[unused203]': 208,\n",
              " '[unused204]': 209,\n",
              " '[unused205]': 210,\n",
              " '[unused206]': 211,\n",
              " '[unused207]': 212,\n",
              " '[unused208]': 213,\n",
              " '[unused209]': 214,\n",
              " '[unused210]': 215,\n",
              " '[unused211]': 216,\n",
              " '[unused212]': 217,\n",
              " '[unused213]': 218,\n",
              " '[unused214]': 219,\n",
              " '[unused215]': 220,\n",
              " '[unused216]': 221,\n",
              " '[unused217]': 222,\n",
              " '[unused218]': 223,\n",
              " '[unused219]': 224,\n",
              " '[unused220]': 225,\n",
              " '[unused221]': 226,\n",
              " '[unused222]': 227,\n",
              " '[unused223]': 228,\n",
              " '[unused224]': 229,\n",
              " '[unused225]': 230,\n",
              " '[unused226]': 231,\n",
              " '[unused227]': 232,\n",
              " '[unused228]': 233,\n",
              " '[unused229]': 234,\n",
              " '[unused230]': 235,\n",
              " '[unused231]': 236,\n",
              " '[unused232]': 237,\n",
              " '[unused233]': 238,\n",
              " '[unused234]': 239,\n",
              " '[unused235]': 240,\n",
              " '[unused236]': 241,\n",
              " '[unused237]': 242,\n",
              " '[unused238]': 243,\n",
              " '[unused239]': 244,\n",
              " '[unused240]': 245,\n",
              " '[unused241]': 246,\n",
              " '[unused242]': 247,\n",
              " '[unused243]': 248,\n",
              " '[unused244]': 249,\n",
              " '[unused245]': 250,\n",
              " '[unused246]': 251,\n",
              " '[unused247]': 252,\n",
              " '[unused248]': 253,\n",
              " '[unused249]': 254,\n",
              " '[unused250]': 255,\n",
              " '[unused251]': 256,\n",
              " '[unused252]': 257,\n",
              " '[unused253]': 258,\n",
              " '[unused254]': 259,\n",
              " '[unused255]': 260,\n",
              " '[unused256]': 261,\n",
              " '[unused257]': 262,\n",
              " '[unused258]': 263,\n",
              " '[unused259]': 264,\n",
              " '[unused260]': 265,\n",
              " '[unused261]': 266,\n",
              " '[unused262]': 267,\n",
              " '[unused263]': 268,\n",
              " '[unused264]': 269,\n",
              " '[unused265]': 270,\n",
              " '[unused266]': 271,\n",
              " '[unused267]': 272,\n",
              " '[unused268]': 273,\n",
              " '[unused269]': 274,\n",
              " '[unused270]': 275,\n",
              " '[unused271]': 276,\n",
              " '[unused272]': 277,\n",
              " '[unused273]': 278,\n",
              " '[unused274]': 279,\n",
              " '[unused275]': 280,\n",
              " '[unused276]': 281,\n",
              " '[unused277]': 282,\n",
              " '[unused278]': 283,\n",
              " '[unused279]': 284,\n",
              " '[unused280]': 285,\n",
              " '[unused281]': 286,\n",
              " '[unused282]': 287,\n",
              " '[unused283]': 288,\n",
              " '[unused284]': 289,\n",
              " '[unused285]': 290,\n",
              " '[unused286]': 291,\n",
              " '[unused287]': 292,\n",
              " '[unused288]': 293,\n",
              " '[unused289]': 294,\n",
              " '[unused290]': 295,\n",
              " '[unused291]': 296,\n",
              " '[unused292]': 297,\n",
              " '[unused293]': 298,\n",
              " '[unused294]': 299,\n",
              " '[unused295]': 300,\n",
              " '[unused296]': 301,\n",
              " '[unused297]': 302,\n",
              " '[unused298]': 303,\n",
              " '[unused299]': 304,\n",
              " '[unused300]': 305,\n",
              " '[unused301]': 306,\n",
              " '[unused302]': 307,\n",
              " '[unused303]': 308,\n",
              " '[unused304]': 309,\n",
              " '[unused305]': 310,\n",
              " '[unused306]': 311,\n",
              " '[unused307]': 312,\n",
              " '[unused308]': 313,\n",
              " '[unused309]': 314,\n",
              " '[unused310]': 315,\n",
              " '[unused311]': 316,\n",
              " '[unused312]': 317,\n",
              " '[unused313]': 318,\n",
              " '[unused314]': 319,\n",
              " '[unused315]': 320,\n",
              " '[unused316]': 321,\n",
              " '[unused317]': 322,\n",
              " '[unused318]': 323,\n",
              " '[unused319]': 324,\n",
              " '[unused320]': 325,\n",
              " '[unused321]': 326,\n",
              " '[unused322]': 327,\n",
              " '[unused323]': 328,\n",
              " '[unused324]': 329,\n",
              " '[unused325]': 330,\n",
              " '[unused326]': 331,\n",
              " '[unused327]': 332,\n",
              " '[unused328]': 333,\n",
              " '[unused329]': 334,\n",
              " '[unused330]': 335,\n",
              " '[unused331]': 336,\n",
              " '[unused332]': 337,\n",
              " '[unused333]': 338,\n",
              " '[unused334]': 339,\n",
              " '[unused335]': 340,\n",
              " '[unused336]': 341,\n",
              " '[unused337]': 342,\n",
              " '[unused338]': 343,\n",
              " '[unused339]': 344,\n",
              " '[unused340]': 345,\n",
              " '[unused341]': 346,\n",
              " '[unused342]': 347,\n",
              " '[unused343]': 348,\n",
              " '[unused344]': 349,\n",
              " '[unused345]': 350,\n",
              " '[unused346]': 351,\n",
              " '[unused347]': 352,\n",
              " '[unused348]': 353,\n",
              " '[unused349]': 354,\n",
              " '[unused350]': 355,\n",
              " '[unused351]': 356,\n",
              " '[unused352]': 357,\n",
              " '[unused353]': 358,\n",
              " '[unused354]': 359,\n",
              " '[unused355]': 360,\n",
              " '[unused356]': 361,\n",
              " '[unused357]': 362,\n",
              " '[unused358]': 363,\n",
              " '[unused359]': 364,\n",
              " '[unused360]': 365,\n",
              " '[unused361]': 366,\n",
              " '[unused362]': 367,\n",
              " '[unused363]': 368,\n",
              " '[unused364]': 369,\n",
              " '[unused365]': 370,\n",
              " '[unused366]': 371,\n",
              " '[unused367]': 372,\n",
              " '[unused368]': 373,\n",
              " '[unused369]': 374,\n",
              " '[unused370]': 375,\n",
              " '[unused371]': 376,\n",
              " '[unused372]': 377,\n",
              " '[unused373]': 378,\n",
              " '[unused374]': 379,\n",
              " '[unused375]': 380,\n",
              " '[unused376]': 381,\n",
              " '[unused377]': 382,\n",
              " '[unused378]': 383,\n",
              " '[unused379]': 384,\n",
              " '[unused380]': 385,\n",
              " '[unused381]': 386,\n",
              " '[unused382]': 387,\n",
              " '[unused383]': 388,\n",
              " '[unused384]': 389,\n",
              " '[unused385]': 390,\n",
              " '[unused386]': 391,\n",
              " '[unused387]': 392,\n",
              " '[unused388]': 393,\n",
              " '[unused389]': 394,\n",
              " '[unused390]': 395,\n",
              " '[unused391]': 396,\n",
              " '[unused392]': 397,\n",
              " '[unused393]': 398,\n",
              " '[unused394]': 399,\n",
              " '[unused395]': 400,\n",
              " '[unused396]': 401,\n",
              " '[unused397]': 402,\n",
              " '[unused398]': 403,\n",
              " '[unused399]': 404,\n",
              " '[unused400]': 405,\n",
              " '[unused401]': 406,\n",
              " '[unused402]': 407,\n",
              " '[unused403]': 408,\n",
              " '[unused404]': 409,\n",
              " '[unused405]': 410,\n",
              " '[unused406]': 411,\n",
              " '[unused407]': 412,\n",
              " '[unused408]': 413,\n",
              " '[unused409]': 414,\n",
              " '[unused410]': 415,\n",
              " '[unused411]': 416,\n",
              " '[unused412]': 417,\n",
              " '[unused413]': 418,\n",
              " '[unused414]': 419,\n",
              " '[unused415]': 420,\n",
              " '[unused416]': 421,\n",
              " '[unused417]': 422,\n",
              " '[unused418]': 423,\n",
              " '[unused419]': 424,\n",
              " '[unused420]': 425,\n",
              " '[unused421]': 426,\n",
              " '[unused422]': 427,\n",
              " '[unused423]': 428,\n",
              " '[unused424]': 429,\n",
              " '[unused425]': 430,\n",
              " '[unused426]': 431,\n",
              " '[unused427]': 432,\n",
              " '[unused428]': 433,\n",
              " '[unused429]': 434,\n",
              " '[unused430]': 435,\n",
              " '[unused431]': 436,\n",
              " '[unused432]': 437,\n",
              " '[unused433]': 438,\n",
              " '[unused434]': 439,\n",
              " '[unused435]': 440,\n",
              " '[unused436]': 441,\n",
              " '[unused437]': 442,\n",
              " '[unused438]': 443,\n",
              " '[unused439]': 444,\n",
              " '[unused440]': 445,\n",
              " '[unused441]': 446,\n",
              " '[unused442]': 447,\n",
              " '[unused443]': 448,\n",
              " '[unused444]': 449,\n",
              " '[unused445]': 450,\n",
              " '[unused446]': 451,\n",
              " '[unused447]': 452,\n",
              " '[unused448]': 453,\n",
              " '[unused449]': 454,\n",
              " '[unused450]': 455,\n",
              " '[unused451]': 456,\n",
              " '[unused452]': 457,\n",
              " '[unused453]': 458,\n",
              " '[unused454]': 459,\n",
              " '[unused455]': 460,\n",
              " '[unused456]': 461,\n",
              " '[unused457]': 462,\n",
              " '[unused458]': 463,\n",
              " '[unused459]': 464,\n",
              " '[unused460]': 465,\n",
              " '[unused461]': 466,\n",
              " '[unused462]': 467,\n",
              " '[unused463]': 468,\n",
              " '[unused464]': 469,\n",
              " '[unused465]': 470,\n",
              " '[unused466]': 471,\n",
              " '[unused467]': 472,\n",
              " '[unused468]': 473,\n",
              " '[unused469]': 474,\n",
              " '[unused470]': 475,\n",
              " '[unused471]': 476,\n",
              " '[unused472]': 477,\n",
              " '[unused473]': 478,\n",
              " '[unused474]': 479,\n",
              " '[unused475]': 480,\n",
              " '[unused476]': 481,\n",
              " '[unused477]': 482,\n",
              " '[unused478]': 483,\n",
              " '[unused479]': 484,\n",
              " '[unused480]': 485,\n",
              " '[unused481]': 486,\n",
              " '[unused482]': 487,\n",
              " '[unused483]': 488,\n",
              " '[unused484]': 489,\n",
              " '[unused485]': 490,\n",
              " '[unused486]': 491,\n",
              " '[unused487]': 492,\n",
              " '[unused488]': 493,\n",
              " '[unused489]': 494,\n",
              " '[unused490]': 495,\n",
              " '[unused491]': 496,\n",
              " '[unused492]': 497,\n",
              " '[unused493]': 498,\n",
              " '[unused494]': 499,\n",
              " '[unused495]': 500,\n",
              " '[unused496]': 501,\n",
              " '[unused497]': 502,\n",
              " '[unused498]': 503,\n",
              " '[unused499]': 504,\n",
              " '[unused500]': 505,\n",
              " '[unused501]': 506,\n",
              " '[unused502]': 507,\n",
              " '[unused503]': 508,\n",
              " '[unused504]': 509,\n",
              " '[unused505]': 510,\n",
              " '[unused506]': 511,\n",
              " '[unused507]': 512,\n",
              " '[unused508]': 513,\n",
              " '[unused509]': 514,\n",
              " '[unused510]': 515,\n",
              " '[unused511]': 516,\n",
              " '[unused512]': 517,\n",
              " '[unused513]': 518,\n",
              " '[unused514]': 519,\n",
              " '[unused515]': 520,\n",
              " '[unused516]': 521,\n",
              " '[unused517]': 522,\n",
              " '[unused518]': 523,\n",
              " '[unused519]': 524,\n",
              " '[unused520]': 525,\n",
              " '[unused521]': 526,\n",
              " '[unused522]': 527,\n",
              " '[unused523]': 528,\n",
              " '[unused524]': 529,\n",
              " '[unused525]': 530,\n",
              " '[unused526]': 531,\n",
              " '[unused527]': 532,\n",
              " '[unused528]': 533,\n",
              " '[unused529]': 534,\n",
              " '[unused530]': 535,\n",
              " '[unused531]': 536,\n",
              " '[unused532]': 537,\n",
              " '[unused533]': 538,\n",
              " '[unused534]': 539,\n",
              " '[unused535]': 540,\n",
              " '[unused536]': 541,\n",
              " '[unused537]': 542,\n",
              " '[unused538]': 543,\n",
              " '[unused539]': 544,\n",
              " '[unused540]': 545,\n",
              " '[unused541]': 546,\n",
              " '[unused542]': 547,\n",
              " '[unused543]': 548,\n",
              " '[unused544]': 549,\n",
              " '[unused545]': 550,\n",
              " '[unused546]': 551,\n",
              " '[unused547]': 552,\n",
              " '[unused548]': 553,\n",
              " '[unused549]': 554,\n",
              " '[unused550]': 555,\n",
              " '[unused551]': 556,\n",
              " '[unused552]': 557,\n",
              " '[unused553]': 558,\n",
              " '[unused554]': 559,\n",
              " '[unused555]': 560,\n",
              " '[unused556]': 561,\n",
              " '[unused557]': 562,\n",
              " '[unused558]': 563,\n",
              " '[unused559]': 564,\n",
              " '[unused560]': 565,\n",
              " '[unused561]': 566,\n",
              " '[unused562]': 567,\n",
              " '[unused563]': 568,\n",
              " '[unused564]': 569,\n",
              " '[unused565]': 570,\n",
              " '[unused566]': 571,\n",
              " '[unused567]': 572,\n",
              " '[unused568]': 573,\n",
              " '[unused569]': 574,\n",
              " '[unused570]': 575,\n",
              " '[unused571]': 576,\n",
              " '[unused572]': 577,\n",
              " '[unused573]': 578,\n",
              " '[unused574]': 579,\n",
              " '[unused575]': 580,\n",
              " '[unused576]': 581,\n",
              " '[unused577]': 582,\n",
              " '[unused578]': 583,\n",
              " '[unused579]': 584,\n",
              " '[unused580]': 585,\n",
              " '[unused581]': 586,\n",
              " '[unused582]': 587,\n",
              " '[unused583]': 588,\n",
              " '[unused584]': 589,\n",
              " '[unused585]': 590,\n",
              " '[unused586]': 591,\n",
              " '[unused587]': 592,\n",
              " '[unused588]': 593,\n",
              " '[unused589]': 594,\n",
              " '[unused590]': 595,\n",
              " '[unused591]': 596,\n",
              " '[unused592]': 597,\n",
              " '[unused593]': 598,\n",
              " '[unused594]': 599,\n",
              " '[unused595]': 600,\n",
              " '[unused596]': 601,\n",
              " '[unused597]': 602,\n",
              " '[unused598]': 603,\n",
              " '[unused599]': 604,\n",
              " '[unused600]': 605,\n",
              " '[unused601]': 606,\n",
              " '[unused602]': 607,\n",
              " '[unused603]': 608,\n",
              " '[unused604]': 609,\n",
              " '[unused605]': 610,\n",
              " '[unused606]': 611,\n",
              " '[unused607]': 612,\n",
              " '[unused608]': 613,\n",
              " '[unused609]': 614,\n",
              " '[unused610]': 615,\n",
              " '[unused611]': 616,\n",
              " '[unused612]': 617,\n",
              " '[unused613]': 618,\n",
              " '[unused614]': 619,\n",
              " '[unused615]': 620,\n",
              " '[unused616]': 621,\n",
              " '[unused617]': 622,\n",
              " '[unused618]': 623,\n",
              " '[unused619]': 624,\n",
              " '[unused620]': 625,\n",
              " '[unused621]': 626,\n",
              " '[unused622]': 627,\n",
              " '[unused623]': 628,\n",
              " '[unused624]': 629,\n",
              " '[unused625]': 630,\n",
              " '[unused626]': 631,\n",
              " '[unused627]': 632,\n",
              " '[unused628]': 633,\n",
              " '[unused629]': 634,\n",
              " '[unused630]': 635,\n",
              " '[unused631]': 636,\n",
              " '[unused632]': 637,\n",
              " '[unused633]': 638,\n",
              " '[unused634]': 639,\n",
              " '[unused635]': 640,\n",
              " '[unused636]': 641,\n",
              " '[unused637]': 642,\n",
              " '[unused638]': 643,\n",
              " '[unused639]': 644,\n",
              " '[unused640]': 645,\n",
              " '[unused641]': 646,\n",
              " '[unused642]': 647,\n",
              " '[unused643]': 648,\n",
              " '[unused644]': 649,\n",
              " '[unused645]': 650,\n",
              " '[unused646]': 651,\n",
              " '[unused647]': 652,\n",
              " '[unused648]': 653,\n",
              " '[unused649]': 654,\n",
              " '[unused650]': 655,\n",
              " '[unused651]': 656,\n",
              " '[unused652]': 657,\n",
              " '[unused653]': 658,\n",
              " '[unused654]': 659,\n",
              " '[unused655]': 660,\n",
              " '[unused656]': 661,\n",
              " '[unused657]': 662,\n",
              " '[unused658]': 663,\n",
              " '[unused659]': 664,\n",
              " '[unused660]': 665,\n",
              " '[unused661]': 666,\n",
              " '[unused662]': 667,\n",
              " '[unused663]': 668,\n",
              " '[unused664]': 669,\n",
              " '[unused665]': 670,\n",
              " '[unused666]': 671,\n",
              " '[unused667]': 672,\n",
              " '[unused668]': 673,\n",
              " '[unused669]': 674,\n",
              " '[unused670]': 675,\n",
              " '[unused671]': 676,\n",
              " '[unused672]': 677,\n",
              " '[unused673]': 678,\n",
              " '[unused674]': 679,\n",
              " '[unused675]': 680,\n",
              " '[unused676]': 681,\n",
              " '[unused677]': 682,\n",
              " '[unused678]': 683,\n",
              " '[unused679]': 684,\n",
              " '[unused680]': 685,\n",
              " '[unused681]': 686,\n",
              " '[unused682]': 687,\n",
              " '[unused683]': 688,\n",
              " '[unused684]': 689,\n",
              " '[unused685]': 690,\n",
              " '[unused686]': 691,\n",
              " '[unused687]': 692,\n",
              " '[unused688]': 693,\n",
              " '[unused689]': 694,\n",
              " '[unused690]': 695,\n",
              " '[unused691]': 696,\n",
              " '[unused692]': 697,\n",
              " '[unused693]': 698,\n",
              " '[unused694]': 699,\n",
              " '[unused695]': 700,\n",
              " '[unused696]': 701,\n",
              " '[unused697]': 702,\n",
              " '[unused698]': 703,\n",
              " '[unused699]': 704,\n",
              " '[unused700]': 705,\n",
              " '[unused701]': 706,\n",
              " '[unused702]': 707,\n",
              " '[unused703]': 708,\n",
              " '[unused704]': 709,\n",
              " '[unused705]': 710,\n",
              " '[unused706]': 711,\n",
              " '[unused707]': 712,\n",
              " '[unused708]': 713,\n",
              " '[unused709]': 714,\n",
              " '[unused710]': 715,\n",
              " '[unused711]': 716,\n",
              " '[unused712]': 717,\n",
              " '[unused713]': 718,\n",
              " '[unused714]': 719,\n",
              " '[unused715]': 720,\n",
              " '[unused716]': 721,\n",
              " '[unused717]': 722,\n",
              " '[unused718]': 723,\n",
              " '[unused719]': 724,\n",
              " '[unused720]': 725,\n",
              " '[unused721]': 726,\n",
              " '[unused722]': 727,\n",
              " '[unused723]': 728,\n",
              " '[unused724]': 729,\n",
              " '[unused725]': 730,\n",
              " '[unused726]': 731,\n",
              " '[unused727]': 732,\n",
              " '[unused728]': 733,\n",
              " '[unused729]': 734,\n",
              " '[unused730]': 735,\n",
              " '[unused731]': 736,\n",
              " '[unused732]': 737,\n",
              " '[unused733]': 738,\n",
              " '[unused734]': 739,\n",
              " '[unused735]': 740,\n",
              " '[unused736]': 741,\n",
              " '[unused737]': 742,\n",
              " '[unused738]': 743,\n",
              " '[unused739]': 744,\n",
              " '[unused740]': 745,\n",
              " '[unused741]': 746,\n",
              " '[unused742]': 747,\n",
              " '[unused743]': 748,\n",
              " '[unused744]': 749,\n",
              " '[unused745]': 750,\n",
              " '[unused746]': 751,\n",
              " '[unused747]': 752,\n",
              " '[unused748]': 753,\n",
              " '[unused749]': 754,\n",
              " '[unused750]': 755,\n",
              " '[unused751]': 756,\n",
              " '[unused752]': 757,\n",
              " '[unused753]': 758,\n",
              " '[unused754]': 759,\n",
              " '[unused755]': 760,\n",
              " '[unused756]': 761,\n",
              " '[unused757]': 762,\n",
              " '[unused758]': 763,\n",
              " '[unused759]': 764,\n",
              " '[unused760]': 765,\n",
              " '[unused761]': 766,\n",
              " '[unused762]': 767,\n",
              " '[unused763]': 768,\n",
              " '[unused764]': 769,\n",
              " '[unused765]': 770,\n",
              " '[unused766]': 771,\n",
              " '[unused767]': 772,\n",
              " '[unused768]': 773,\n",
              " '[unused769]': 774,\n",
              " '[unused770]': 775,\n",
              " '[unused771]': 776,\n",
              " '[unused772]': 777,\n",
              " '[unused773]': 778,\n",
              " '[unused774]': 779,\n",
              " '[unused775]': 780,\n",
              " '[unused776]': 781,\n",
              " '[unused777]': 782,\n",
              " '[unused778]': 783,\n",
              " '[unused779]': 784,\n",
              " '[unused780]': 785,\n",
              " '[unused781]': 786,\n",
              " '[unused782]': 787,\n",
              " '[unused783]': 788,\n",
              " '[unused784]': 789,\n",
              " '[unused785]': 790,\n",
              " '[unused786]': 791,\n",
              " '[unused787]': 792,\n",
              " '[unused788]': 793,\n",
              " '[unused789]': 794,\n",
              " '[unused790]': 795,\n",
              " '[unused791]': 796,\n",
              " '[unused792]': 797,\n",
              " '[unused793]': 798,\n",
              " '[unused794]': 799,\n",
              " '[unused795]': 800,\n",
              " '[unused796]': 801,\n",
              " '[unused797]': 802,\n",
              " '[unused798]': 803,\n",
              " '[unused799]': 804,\n",
              " '[unused800]': 805,\n",
              " '[unused801]': 806,\n",
              " '[unused802]': 807,\n",
              " '[unused803]': 808,\n",
              " '[unused804]': 809,\n",
              " '[unused805]': 810,\n",
              " '[unused806]': 811,\n",
              " '[unused807]': 812,\n",
              " '[unused808]': 813,\n",
              " '[unused809]': 814,\n",
              " '[unused810]': 815,\n",
              " '[unused811]': 816,\n",
              " '[unused812]': 817,\n",
              " '[unused813]': 818,\n",
              " '[unused814]': 819,\n",
              " '[unused815]': 820,\n",
              " '[unused816]': 821,\n",
              " '[unused817]': 822,\n",
              " '[unused818]': 823,\n",
              " '[unused819]': 824,\n",
              " '[unused820]': 825,\n",
              " '[unused821]': 826,\n",
              " '[unused822]': 827,\n",
              " '[unused823]': 828,\n",
              " '[unused824]': 829,\n",
              " '[unused825]': 830,\n",
              " '[unused826]': 831,\n",
              " '[unused827]': 832,\n",
              " '[unused828]': 833,\n",
              " '[unused829]': 834,\n",
              " '[unused830]': 835,\n",
              " '[unused831]': 836,\n",
              " '[unused832]': 837,\n",
              " '[unused833]': 838,\n",
              " '[unused834]': 839,\n",
              " '[unused835]': 840,\n",
              " '[unused836]': 841,\n",
              " '[unused837]': 842,\n",
              " '[unused838]': 843,\n",
              " '[unused839]': 844,\n",
              " '[unused840]': 845,\n",
              " '[unused841]': 846,\n",
              " '[unused842]': 847,\n",
              " '[unused843]': 848,\n",
              " '[unused844]': 849,\n",
              " '[unused845]': 850,\n",
              " '[unused846]': 851,\n",
              " '[unused847]': 852,\n",
              " '[unused848]': 853,\n",
              " '[unused849]': 854,\n",
              " '[unused850]': 855,\n",
              " '[unused851]': 856,\n",
              " '[unused852]': 857,\n",
              " '[unused853]': 858,\n",
              " '[unused854]': 859,\n",
              " '[unused855]': 860,\n",
              " '[unused856]': 861,\n",
              " '[unused857]': 862,\n",
              " '[unused858]': 863,\n",
              " '[unused859]': 864,\n",
              " '[unused860]': 865,\n",
              " '[unused861]': 866,\n",
              " '[unused862]': 867,\n",
              " '[unused863]': 868,\n",
              " '[unused864]': 869,\n",
              " '[unused865]': 870,\n",
              " '[unused866]': 871,\n",
              " '[unused867]': 872,\n",
              " '[unused868]': 873,\n",
              " '[unused869]': 874,\n",
              " '[unused870]': 875,\n",
              " '[unused871]': 876,\n",
              " '[unused872]': 877,\n",
              " '[unused873]': 878,\n",
              " '[unused874]': 879,\n",
              " '[unused875]': 880,\n",
              " '[unused876]': 881,\n",
              " '[unused877]': 882,\n",
              " '[unused878]': 883,\n",
              " '[unused879]': 884,\n",
              " '[unused880]': 885,\n",
              " '[unused881]': 886,\n",
              " '[unused882]': 887,\n",
              " '[unused883]': 888,\n",
              " '[unused884]': 889,\n",
              " '[unused885]': 890,\n",
              " '[unused886]': 891,\n",
              " '[unused887]': 892,\n",
              " '[unused888]': 893,\n",
              " '[unused889]': 894,\n",
              " '[unused890]': 895,\n",
              " '[unused891]': 896,\n",
              " '[unused892]': 897,\n",
              " '[unused893]': 898,\n",
              " '[unused894]': 899,\n",
              " '[unused895]': 900,\n",
              " '[unused896]': 901,\n",
              " '[unused897]': 902,\n",
              " '[unused898]': 903,\n",
              " '[unused899]': 904,\n",
              " '[unused900]': 905,\n",
              " '[unused901]': 906,\n",
              " '[unused902]': 907,\n",
              " '[unused903]': 908,\n",
              " '[unused904]': 909,\n",
              " '[unused905]': 910,\n",
              " '[unused906]': 911,\n",
              " '[unused907]': 912,\n",
              " '[unused908]': 913,\n",
              " '[unused909]': 914,\n",
              " '[unused910]': 915,\n",
              " '[unused911]': 916,\n",
              " '[unused912]': 917,\n",
              " '[unused913]': 918,\n",
              " '[unused914]': 919,\n",
              " '[unused915]': 920,\n",
              " '[unused916]': 921,\n",
              " '[unused917]': 922,\n",
              " '[unused918]': 923,\n",
              " '[unused919]': 924,\n",
              " '[unused920]': 925,\n",
              " '[unused921]': 926,\n",
              " '[unused922]': 927,\n",
              " '[unused923]': 928,\n",
              " '[unused924]': 929,\n",
              " '[unused925]': 930,\n",
              " '[unused926]': 931,\n",
              " '[unused927]': 932,\n",
              " '[unused928]': 933,\n",
              " '[unused929]': 934,\n",
              " '[unused930]': 935,\n",
              " '[unused931]': 936,\n",
              " '[unused932]': 937,\n",
              " '[unused933]': 938,\n",
              " '[unused934]': 939,\n",
              " '[unused935]': 940,\n",
              " '[unused936]': 941,\n",
              " '[unused937]': 942,\n",
              " '[unused938]': 943,\n",
              " '[unused939]': 944,\n",
              " '[unused940]': 945,\n",
              " '[unused941]': 946,\n",
              " '[unused942]': 947,\n",
              " '[unused943]': 948,\n",
              " '[unused944]': 949,\n",
              " '[unused945]': 950,\n",
              " '[unused946]': 951,\n",
              " '[unused947]': 952,\n",
              " '[unused948]': 953,\n",
              " '[unused949]': 954,\n",
              " '[unused950]': 955,\n",
              " '[unused951]': 956,\n",
              " '[unused952]': 957,\n",
              " '[unused953]': 958,\n",
              " '[unused954]': 959,\n",
              " '[unused955]': 960,\n",
              " '[unused956]': 961,\n",
              " '[unused957]': 962,\n",
              " '[unused958]': 963,\n",
              " '[unused959]': 964,\n",
              " '[unused960]': 965,\n",
              " '[unused961]': 966,\n",
              " '[unused962]': 967,\n",
              " '[unused963]': 968,\n",
              " '[unused964]': 969,\n",
              " '[unused965]': 970,\n",
              " '[unused966]': 971,\n",
              " '[unused967]': 972,\n",
              " '[unused968]': 973,\n",
              " '[unused969]': 974,\n",
              " '[unused970]': 975,\n",
              " '[unused971]': 976,\n",
              " '[unused972]': 977,\n",
              " '[unused973]': 978,\n",
              " '[unused974]': 979,\n",
              " '[unused975]': 980,\n",
              " '[unused976]': 981,\n",
              " '[unused977]': 982,\n",
              " '[unused978]': 983,\n",
              " '[unused979]': 984,\n",
              " '[unused980]': 985,\n",
              " '[unused981]': 986,\n",
              " '[unused982]': 987,\n",
              " '[unused983]': 988,\n",
              " '[unused984]': 989,\n",
              " '[unused985]': 990,\n",
              " '[unused986]': 991,\n",
              " '[unused987]': 992,\n",
              " '[unused988]': 993,\n",
              " '[unused989]': 994,\n",
              " '[unused990]': 995,\n",
              " '[unused991]': 996,\n",
              " '[unused992]': 997,\n",
              " '[unused993]': 998,\n",
              " '!': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class inherit_Tokenizer(Tokenizer):\n",
        "  def _tokenize(self, text):\n",
        "    if not self._cased:\n",
        "      text = text\n",
        "\n",
        "      text = text.lower()\n",
        "\n",
        "    spaced = ''\n",
        "    for ch in text:\n",
        "      if self._is_punctuation(ch) or self._is_cjk_character(ch):\n",
        "        spaced += ' ' + ch + ' '\n",
        "      elif self._is_space(ch):\n",
        "        spaced += ' '\n",
        "      elif ord(ch) == 0 or ord(ch) == 0xfffd or self._is_control(ch):\n",
        "        continue\n",
        "      else:\n",
        "        spaced += ch\n",
        "      tokens = []\n",
        "    for word in spaced.strip().split():\n",
        "      tokens += self._word_piece_tokenize(word)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "K1BB3Yk3Curi"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = inherit_Tokenizer(token_dict)"
      ],
      "metadata": {
        "id": "tWGjVbhSCwZ8"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize('이번에 NH투자증권 공모전 나가면 좋은 경험이 될거야.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ex5YlH1ACxps",
        "outputId": "74a2eaeb-bf42-4c6c-f94d-048dd9ff425d"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=13, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['content'][16]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "In0dZFb-Czzc",
        "outputId": "06c4778a-2afe-4f6e-eb29-8a4844dfde4c"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' for working in vineyards, orchards, or the like'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(train['content'][16])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv7RcvDzDC5b",
        "outputId": "ddd28d81-e215-4bda-cccc-9d9f0f602ebf"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoding(num_tokens=12, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data(data_df):\n",
        "  global tokenizer\n",
        "  indices, targets = [], []\n",
        "  for i in tqdm(range(len(data_df))):\n",
        "    ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
        "    indices.append(ids)\n",
        "    targets.append(data_df[LABEL_COLUMN][i])\n",
        "\n",
        "  items = list(zip(indices, targets))\n",
        "\n",
        "  indices, targets = zip(*items)\n",
        "  indices = np.array(indices)\n",
        "  return [indices, np.zeros_like(indices)], np.array(targets)\n",
        "\n",
        "def load_data(pandas_dataframe):\n",
        "  data_df = pandas_dataframe\n",
        "  data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "\n",
        "  data_x, data_y = convert_data(data_df)\n",
        "\n",
        "  return data_x, data_y"
      ],
      "metadata": {
        "id": "fN7D_ocNDJqH"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, train_y = load_data(train)"
      ],
      "metadata": {
        "id": "kLiDNSjPDOTh",
        "outputId": "9f9d2aaf-4d5c-4a1d-ade5-a94120fcb90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/67359 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-13983f15cfb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-116-d1059a490a42>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(pandas_dataframe)\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-116-d1059a490a42>\u001b[0m in \u001b[0;36mconvert_data\u001b[0;34m(data_df)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mLABEL_COLUMN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: encode() got an unexpected keyword argument 'max_len'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBhWXvGiJZbN",
        "outputId": "fe10cf0a-fd02-4d1d-e7dd-eb6d9f7eaa2e"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[  101,  2192,  5906, ...,     0,     0,     0],\n",
              "        [  101, 23288,  2015, ...,     0,     0,     0],\n",
              "        [  101,  2007,  4091, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [  101, 14709,  2030, ...,     0,     0,     0],\n",
              "        [  101, 17462,  1025, ...,     0,     0,     0],\n",
              "        [  101, 12318,  1996, ...,     0,     0,     0]]),\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_convert_data(data):\n",
        "  global tokenizer\n",
        "  indices = []\n",
        "  for i in tqdm(range(len(data))):\n",
        "    print(tokenizer.tokenize(data[i]))\n",
        "    ids, segments = tokenizer.encode(data[i], max_len = SEQ_LEN)\n",
        "    indices.append(ids)\n",
        "\n",
        "  items = indices\n",
        "  indices = np.array(indices)\n",
        "  return [indices, np.zeros_like(indices)]\n",
        "\n",
        "def sentence_load_data(sentences): #sentence는 list input\n",
        "\n",
        "  data_x = sentence_convert_data(sentences)\n",
        "\n",
        "  return data_x"
      ],
      "metadata": {
        "id": "I_hcKidCJieI"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_load_data([\"오늘 날씨는 맑음\", \"내일 아침은 토스트를 먹을거야\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u02JkT2EJmiN",
        "outputId": "0c297395-7860-4e7c-d008-b9f57ebe874e"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 3230.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', '오', '##늘', '날', '##씨', '##는', '맑', '##음', '[SEP]']\n",
            "['[CLS]', '내', '##일', '아', '##침', '##은', '토', '##스', '##트', '##를', '먹', '##을', '##거', '##야', '[SEP]']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[101, 100, 100, 100, 100, 100, 100, 100, 102,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "        [101, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "         100, 102,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]]),\n",
              " array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델정의\n",
        "layer_num = 12\n",
        "model = load_trained_model_from_checkpoint(\n",
        "    config_path,\n",
        "    checkpoint_path,\n",
        "    training = True,\n",
        "    trainable = True,\n",
        "    seq_len = SEQ_LEN\n",
        ")"
      ],
      "metadata": {
        "id": "BX9M5kh5Jqdq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "4e80b99f-7028-4b09-be89-0e752b1f7b21"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-fc84d6fa257a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtraining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSEQ_LEN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_bert/loader.py\u001b[0m in \u001b[0;36mload_trained_model_from_checkpoint\u001b[0;34m(config_file, checkpoint_file, training, trainable, output_layer_num, seq_len, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0moutput_layer_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_layer_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mseq_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0mload_model_weights_from_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_bert/loader.py\u001b[0m in \u001b[0;36mbuild_model_from_config\u001b[0;34m(config_file, training, trainable, output_layer_num, seq_len, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_position_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_position_embeddings'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'max_position_embeddings'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "LCvaSSoFJuNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
      ],
      "metadata": {
        "id": "cfSaCEChJxLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bert_finetuning_model(model):\n",
        "  inputs = model.inputs[:2]\n",
        "  dense = model.layers[-3].output\n",
        "\n",
        "  outputs = keras.layers.Dense(1, activation = 'relu', kernel_initializer = keras.initializers.TruncatedNormal(stddev=0.02),\n",
        "                              name = 'real_output')(dense) #밑에 두개의 layer를 제외하고 output layer를 붙여줌\n",
        "\n",
        "  bert_model = keras.models.Model(inputs, outputs)\n",
        "  Adam = tf.keras.optimizers.Adam(lr=0.00001)\n",
        "  bert_model.compile(\n",
        "      optimizer = Adam,\n",
        "      loss = 'mae',\n",
        "      metrics = ['accuracy'])\n",
        "  \n",
        "  return bert_model"
      ],
      "metadata": {
        "id": "IoTea7kzJ0Q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG"
      ],
      "metadata": {
        "id": "kNwfaxIRJ7qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import model_to_dot"
      ],
      "metadata": {
        "id": "1kp_PfmeKB9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SVG(model_to_dot(get_bert_finetuning_model(model), dpi = 65).create(prog='dot', format='svg'))"
      ],
      "metadata": {
        "id": "MeGt-XorK-wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = get_bert_finetuning_model(model)\n",
        "history = bert_model.fit(train_x, train_y, epochs = 2, batch_size = 32, verbose = 1, shuffle=False)\n",
        "bert_model.save_weights(path + \"/bert1.h5\")"
      ],
      "metadata": {
        "id": "irJNgybcLK7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = get_bert_finetuning_model(model)\n",
        "bert_model.load_weights(path + \"/bert1.h5\")"
      ],
      "metadata": {
        "id": "n5Fjw7dtP4fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    indices = []\n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
        "        indices.append(ids)\n",
        "        \n",
        "    items = indices\n",
        "    \n",
        "    \n",
        "    indices = np.array(indices)\n",
        "    return [indices, np.zeros_like(indices)]\n",
        "\n",
        "def predict_load_data(x): #Pandas Dataframe을 인풋으로 받는다\n",
        "    data_df = x\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_x = predict_convert_data(data_df)\n",
        "\n",
        "    return data_x"
      ],
      "metadata": {
        "id": "mVtaAcCRQDqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "CWRe2bdRQRfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_map(model):\n",
        "  inputs = model.input\n",
        "  outputs = model.layers[-2].output\n",
        "  feature_model = Model(inputs, outputs)\n",
        "  return feature_model"
      ],
      "metadata": {
        "id": "tFSChmccQUet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_feature = get_feature_map(bert_model)"
      ],
      "metadata": {
        "id": "6w_zDzrcQXXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = train['info']"
      ],
      "metadata": {
        "id": "pVnxf7gRQtxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    indices = []\n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        ids, segments = tokenizer.encode(data_df[DATA_COLUMN][i], max_len=SEQ_LEN)\n",
        "        indices.append(ids)\n",
        "        \n",
        "    items = indices\n",
        "    \n",
        "    \n",
        "    indices = np.array(indices)\n",
        "    return [indices, np.zeros_like(indices)]\n",
        "\n",
        "def predict_load_data(x): #Pandas Dataframe을 인풋으로 받는다\n",
        "    data_df = x\n",
        "    \n",
        "    \n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "\n",
        "\n",
        "    data_x = predict_convert_data(data_df)\n",
        "\n",
        "    return data_x"
      ],
      "metadata": {
        "id": "_suDEV5ORx4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = predict_load_data(train)"
      ],
      "metadata": {
        "id": "aNGVicTMRzrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = bert_model.predict(train_set)"
      ],
      "metadata": {
        "id": "v0A6pkIXR300"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_weight_list = bert_feature.predict(train_set)"
      ],
      "metadata": {
        "id": "fXZUNylFSCJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "8d8_Lad3SIrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_embedded = PCA(n_components=256).fit_transform(bert_weight_list)\n",
        "bert_embedded = TSNE(n_components=2).fit_transform(bert_embedded)\n",
        "bert_embedded"
      ],
      "metadata": {
        "id": "to32ROnsSKI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g=pd.DataFrame(bert_embedded)\n",
        "g.to_csv(\"bert_embedded.csv\")"
      ],
      "metadata": {
        "id": "nxUJBHp8SdAY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}